
RAW PROMPT FROM STEAM OF THOUGHT

me, I'm working on a new project called HumanWeb2, and I want to mix Selenium and web browsing with automation with Selenium and GPT-4-VisionPreview to use VisionPreview to see the screen and decide on where to go by also seeing the site code at the same time and having a script parse through the site code, feeding it to the model, showing it the options as well as the image, and then having it function call to a RMA function in Python to execute its actions, click, back, forward, copy, paste kind of actions I want to be able to do. And then on top of that, I want to add mouse control for outside of browser control. So HumanWeb2 will offer using a browser like Chrome and then using your computer with your mouse. So I'll need to design a mouse system to move the mouse. But for now, let's focus on the Selenium plus GPT-4-VisionPreview to see. So I'll have to have a mechanism to view the web page by taking a screenshot of the entire window, but also having some control over the screenshot, maybe custom positioning and sizing of the screen area. But for now, let's just take a screenshot of the window, feed it into the model as a caption saying, here's where you are on the website, where to go next. Also, here is the elements on the page that you can click on, and then use that with a common directive for researching given some criteria, like how many searches it should do, how many websites it should visit, and then how many reports it should generate based off all of that. And the reports are just generated off gathered data. So I want to be able to do this. But it doesn't use Vision to drive it, it just uses Selenium. And I want to mix both into something that is truly autonomous, and then eventually add the mouse control. So help me plan for this.