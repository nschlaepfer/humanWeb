from retry_decorator import retry_on_service_unavailable
import openai
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import os
import time
import concurrent.futures

MODEL_NAME = "gpt-3.5-turbo-16k"
THRESHOLD = 5000

@retry_on_service_unavailable(max_retries=5, backoff_factor=0.5)
def create_chat_completion(model, messages):
    return openai.ChatCompletion.create(model=model, messages=messages)

def generate_additional_queries(query, num_queries, debug_log, initial_query):
    print("Generating additional queries with GPT-3...")
    system_prompt = f"Given this query, come up with {num_queries} queries that will help get the most information or complete a task in order. These are to be used in an upcoming report."
    additional_queries = process_with_gpt3(system_prompt, query).split('\n')[:num_queries]
    debug_log.write(f"Generated additional queries: {additional_queries}\n")
    os.makedirs(initial_query, exist_ok=True)
    with open(f"{initial_query}/generated_queries.txt", "w") as f:
        for query in additional_queries:
            f.write(f"{query}\n")
    return additional_queries

def perform_search(query, driver):
    print(f"Performing search for '{query}'...")
    driver.get("https://www.google.com")
    try:
        search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, "q")))
        search_box.send_keys(query)
        search_box.send_keys(Keys.RETURN)
        print("Waiting for search results to load...")
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.g")))
    except Exception as e:
        print(f"Error performing search: {e}")
        return None
    return driver.find_elements(By.CSS_SELECTOR, "div.g")

def extract_search_results(query, num_results, filename, summary_filename, driver):
    print("Extracting search results...")
    search_results = perform_search(query, driver)
    if search_results is None:
        print("No search results found.")
        return []
    search_results = search_results[:num_results]
    os.makedirs("Searches", exist_ok=True)
    links = []
    with open(filename, "w") as f:
        for i, result in enumerate(search_results, start=1):
            try:
                title = result.find_element(By.CSS_SELECTOR, "h3").text
                link = result.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
                snippet = result.find_element(By.CSS_SELECTOR, ".rc .s .st").text
                print(f"Result {i}: {title} ({link})")
                f.write(f"Result {i}: {title} ({link})\n")
                links.append((title, link, snippet))
            except Exception as e:
                print(f"Error extracting result {i}: {e}")
    return links

def process_results_with_gpt3(title, link, snippet, summary_filename, initial_query):
    print("Processing results with GPT-3...")
    try:
        system_prompt = f"Given the following information, extract unique and interesting facts and analytical information. Do not just summarize it. This will be used in an upcoming report about {initial_query}. If the information is already known in the content, please do not repeat it. Look at the context given. MUST have sources at bottom."
        gpt_response = process_with_gpt3(system_prompt, snippet)
        summary = f"\n## {title}\n\nSource: [{link}]({link})\n\nGPT-3 Summary: {gpt_response}\n"
        with open(summary_filename, "a") as sf:
            sf.write(summary)
        return summary
    except FileNotFoundError:
        print(f"Could not find file: {summary_filename}")
        return None

def create_report(query, initial_query, summaries):
    print("Creating report...")
    system_prompt = f"Given the following information, create a report with the information and be sure to cite sources. This a professional report. This is about: {initial_query}."
    gpt_report = process_with_gpt3(system_prompt, "\n".join(summaries))
    os.makedirs(f"Reports/{initial_query}", exist_ok=True)
    report_filename = os.path.join("Reports", initial_query, f"Report_{query}_{time.time()}.md")
    with open(report_filename, "w") as rf:
        rf.write(f"# GPT-3 Report:\n\n{gpt_report}\n\nReport generated by: Momo AI\n")
        print(f"Report saved to: {report_filename}")   
    return gpt_report

# Multi-threaded python
def main(query, num_results, driver, initial_query):
    filename = os.path.join(f"Searches/{initial_query}", f"{query}_{time.time()}.txt")
    summary_filename = os.path.join(f"Searches/{initial_query}", f"Summary_{query}_{time.time()}.txt")
    links = extract_search_results(query, num_results, filename, summary_filename, driver)
    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = [executor.submit(process_results_with_gpt3, title, link, snippet, summary_filename, initial_query) for title, link, snippet in links]
        summaries = [f.result() for f in concurrent.futures.as_completed(futures) if f.result() is not None]
    return create_report(query, initial_query, summaries)


# Working. Not fastest enouhg

# # gpt3_functions.py
# from retry_decorator import retry_on_service_unavailable
# import openai
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.webdriver.common.by import By
# from selenium.webdriver.common.keys import Keys
# import os
# import time

# all_summaries = []


# @retry_on_service_unavailable(max_retries=5, backoff_factor=0.5)
# def create_chat_completion(*args, **kwargs):
#     return openai.ChatCompletion.create(*args, **kwargs)




# def generate_additional_queries(query, num_queries, debug_log, initial_query):
#     print("Generating additional queries with GPT-3...")
#     system_prompt = f"Given this query, come up with {num_queries} queries that will help get the most information or complete a task in order. These are to be used in an upcoming report."
#     messages = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': query}]
#     response = openai.ChatCompletion.create(
#         model="gpt-3.5-turbo", #changed since it is smaller
#         messages=messages
#     )
#     additional_queries = response.choices[0].message['content'].strip().split('\n')[:num_queries]
#     # Write to debug log
#     debug_log.write(f"Generated additional queries: {additional_queries}\n")
    
#     # Create the directory if it doesn't exist
#     os.makedirs(initial_query, exist_ok=True)
    
#     # Write the additional queries to a file
#     with open(f"{initial_query}/generated_queries.txt", "w") as f:
#         for query in additional_queries:
#             f.write(f"{query}\n")
    
#     return additional_queries



# def perform_search(query, driver):
#     print(f"Performing search for '{query}'...")
#     driver.get("https://www.google.com")  # Open Google in the browser
#     try:
#         search_box = WebDriverWait(driver, 10).until(
#             EC.presence_of_element_located((By.NAME, "q"))
#         )  # Wait for the search box element to be located
#         search_box.send_keys(query)  # Enter the search query
#         search_box.send_keys(Keys.RETURN)  # Press Enter to perform the search
#         print("Waiting for search results to load...")
#         WebDriverWait(driver, 10).until(
#             EC.presence_of_element_located((By.CSS_SELECTOR, "div.g"))
#         )  # Wait for the search results to load
#     except Exception as e:
#         print(f"Error performing search: {e}")
#         return None
#     return driver.find_elements(By.CSS_SELECTOR, "div.g")

# def extract_search_results(query, num_results, filename, summary_filename, driver, all_summaries, initial_query):
#     print("Extracting search results...")
#     search_results = perform_search(query, driver)
#     if search_results is None:
#         print("No search results found.")
#         return all_summaries
#     search_results = search_results[:num_results]  # Limit to user-specified number of results
#     # Rest of your code...
#     os.makedirs("Searches", exist_ok=True)  # Create the "Searches" directory if it doesn't exist
#     links = []
#     with open(filename, "w") as f:  # Open the output file
#         for i, result in enumerate(search_results, start=1):
#             try:
#                 title = result.find_element(By.CSS_SELECTOR, "h3").text  # Extract the title
#                 link = result.find_element(By.CSS_SELECTOR, "a").get_attribute("href")  # Extract the URL
#                 print(f"Result {i}: {title} ({link})")  # Process the search result as desired
#                 f.write(f"Result {i}: {title} ({link})\n")  # Write the result to the file
#                 links.append((title, link))  # Store the title and link together
#             except Exception as e:
#                 print(f"Error extracting result {i}: {e}")
#         for title, link in links:
#             print("Extracting page content...")
#             driver.set_page_load_timeout(20)  # Set page load timeout
#             try:
#                 driver.get(link)  # Navigate to the page
#                 page_content = driver.find_element(By.TAG_NAME, "body").text  # Extract the text from the body of the page
#                 print(page_content)  # Print the page content
#                 f.write(f"Page Content:\n{page_content}\n")  # Write the page content to the file
#                 print("\n---\n")  # Print a separator
#                 f.write("\n---\n")  # Write a separator to the file
#                 if "Sorry, you have been blocked" not in page_content:  # Check if the page content indicates you've been blocked
#                     gpt_response = process_results_with_gpt3(title, link, page_content, summary_filename, all_summaries, initial_query)
#                     if gpt_response is not None:
#                         print(f"GPT-3 Response: {gpt_response}")
#             except Exception as e:
#                 print(f"Error loading page {link}: {e}")
#     return all_summaries


# def process_results_with_gpt3(title, link, content, summary_filename, all_summaries, initial_query):
#     print("Processing results with GPT-3...")
#     try:
#         system_prompt = f"Given the following information, extract unique and interesting facts and analytical information. Do not just summarize it. This will be used in an upcoming report about {initial_query}. If the information is already known in the content, please do not repeat it. Look at the context given. MUST have sources at bottom."
#         messages = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': content}]
        
#         response = openai.ChatCompletion.create(
#             model="gpt-3.5-turbo-16k", 
#             messages=messages
#         )
#         gpt_response = response.choices[0].message['content'].strip()

#         # Use the GPT-3 response as the final summary
#         summary = f"\n## {title}\n\nSource: [{link}]({link})\n\nGPT-3 Summary: {gpt_response}\n"
#         all_summaries.append(summary)  # Add the summary to the list
#         with open(summary_filename, "a") as sf:  # Open the summary file
#             sf.write(summary)  # Write the GPT-3 summary to the summary file
#     except FileNotFoundError:
#         print(f"Could not find file: {summary_filename}")
#         return all_summaries
#     return all_summaries



# @retry_on_service_unavailable(max_retries=5, backoff_factor=0.5)
# def create_report(query, initial_query, num_results, driver):
#     global all_summaries  # Declare all_summaries as global so we can modify it
#     print("Creating report...")
#     summaries = "\n".join(all_summaries)  # Combine all the summaries into a single string
#     system_prompt = f"Given the following information, create a report with the information and be sure to cite sources. This a professional report. This is about: {initial_query}."
#     messages = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': summaries}]

#     best_report = None
#     best_score = -1

#     # Generate 3 reports
#     for _ in range(3):
#         response = openai.ChatCompletion.create(
#             model="gpt-3.5-turbo-16k",
#             messages=messages
#         )
#         gpt_report = response.choices[0].message['content'].strip()

#         # Researcher step
#         researcher_prompt = "You are a researcher tasked with investigating the report. List the flaws and faulty logic of the report. Make sure every response has sorces and inline citations Let's work this out in a step by step way to be sure we have all the errors:"
#         researcher_messages = [{'role': 'system', 'content': researcher_prompt}, {'role': 'user', 'content': gpt_report}]
#         researcher_response = openai.ChatCompletion.create(
#             model="gpt-3.5-turbo-16k",
#             messages=researcher_messages
#         )
#         researcher_output = researcher_response.choices[0].message['content'].strip()

#         # Resolver step
#         resolver_prompt = f"You are a resolver tasked with improving the report. Print the improved report in full. Let's work this out in a step by step way to be sure we have the right report use the goal: {initial_query} and data resarched {all_summaries} to provide the best report possible.:"
#         resolver_messages = [{'role': 'system', 'content': resolver_prompt}, {'role': 'user', 'content': researcher_output}]
#         resolver_response = openai.ChatCompletion.create(
#             model="gpt-3.5-turbo-16k",
#             messages=resolver_messages
#         )
#         resolver_output = resolver_response.choices[0].message['content'].strip()

#         # Score the resolver output (you can replace this with your own scoring function)
#         score = len(resolver_output)

#         # If this output is better than the current best, update the best output and score
#         if score > best_score:
#             best_report = resolver_output
#             best_score = score

#     # If the best score is below a certain threshold, restart the entire search process
#     THRESHOLD = 5000  # Set the threshold here
#     if best_score < THRESHOLD:
#         print("Report not satisfactory, restarting the search process...")
#         all_summaries = []  # Clear the all_summaries list
#         # Reset other variables as necessary here
#         # Call your search function here to restart the search process
#         # You might need to modify your search function to return the final report
#         filename = os.path.join(f"Searches/{initial_query}", f"{query}_{time.time()}.txt")  # Store the filename
#         summary_filename = os.path.join(f"Searches/{initial_query}", f"Summary_{query}_{time.time()}.txt")  # Store the summary filename
#         return extract_search_results(query, num_results, filename, summary_filename, driver, all_summaries, initial_query)


#     print(f"GPT-3 Report: {best_report}")
#     os.makedirs(f"Reports/{initial_query}", exist_ok=True)  # Create the "Reports" directory if it doesn't exist
#     report_filename = os.path.join("Reports", initial_query, f"Report_{query}_{time.time()}.md")  # Store the report filename
#     with open(report_filename, "w") as rf:  # Open the report file
#         rf.write(f"# GPT-3 Report:\n\n{best_report}\n\nReport generated by: Momo AI\n")  # Write the GPT-3 report to the report file
#         print(f"Report saved to: {report_filename}")   

#     return best_report