# QA.py
from openai import OpenAI

client = OpenAI()
import os
import time

def create_qa(query, summary_filename):
    print("Creating QA...")
    try:
        with open(summary_filename, "r") as sf:  # Open the summary file
            summaries = sf.read()
            messages = [{'role': 'system', 'content': summaries}, {'role': 'user', 'content': f"How well does this report answer the query '{query}' on a scale of 1-10? If the rating is less than 10, why?"}]
            response = client.chat.completions.create(model="gpt-4-vision-preview",
            messages=messages)
            gpt_qa = response.choices[0].message.content.strip()
            print(f"humanWeb QA: {gpt_qa}")
            os.makedirs("QA", exist_ok=True)  # Create the "QA" directory if it doesn't exist
            qa_filename = os.path.join("QA", f"QA_{query}_{time.time()}.txt")  # Store the QA filename
            with open(qa_filename, "w") as qf:  # Open the QA file
                qf.write(f"humanWeb QA:\n{gpt_qa}\n")  # Write the GPT-3 QA to the QA file
    except FileNotFoundError:
        print(f"Could not find file: {summary_filename}")
        return None
    return gpt_qa  # Return the query generated by a LLM
